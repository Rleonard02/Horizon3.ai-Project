services:
  llm:
    build:
      context: .
    image: llama32_11b-llm
    container_name: llm
    volumes:
      - /home/opc/Horizon3.ai-Project/Backend/Sprint1Arsh/myproject/myproject/binary_diff_module/shared_data/c_source/version2/main.c:/app/input_code.txt
      - ./analysis_output.md:/app/analysis_output.md
    environment:
      HUGGINGFACE_API_TOKEN: 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
    command: [ "python", "test_llm_module.py", "input_code.txt" ]
